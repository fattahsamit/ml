{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "687fe8b7",
   "metadata": {},
   "source": [
    "# The Complete Convolutional Neural Network with Python 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42260868",
   "metadata": {},
   "source": [
    "Artificial Neural Network (ANN)\n",
    "\n",
    "The structure of the neural network contains the input layer, hidden layer and output layer. So, normally the information will be received by the input signal and then it will be trasferred to the hidden layers where all the information will be processed. Finally, after processing all information, output will be be released by the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b399581e",
   "metadata": {},
   "source": [
    "Convolutional Neural Network (CNN)\n",
    "\n",
    "CNNs are ANNs. CNNs are made of neurons that are connected to one another by weighted brances (weight); the training parameters of the networks are once again the weight and bias. In CNNs, the connection pattern between neurons is inspired by the structure of the visual cortex in the animal world. The individual neurons that are present in this part of the brain (visual cortex) respond to certain stimuli in a narrow region of the observation, called the receptive field.\n",
    "\n",
    "The receptive fields of different neurons are partially overlapped to cover the entire field of vision. The response of a single neuron to stimuli taking place in it's receptive field can be mathematically approximated by a convolutional operation.\n",
    "\n",
    "CNNs contain input layers, convolution layers, pooling layers, fully connected layers and output layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad07866",
   "metadata": {},
   "source": [
    "Convolution Layer\n",
    "\n",
    "This is the main type of layer; the use of one or more of these layers in CNNs are essential. Convolution layers have neurons which are organized in 3 dimensons:\n",
    "\n",
    "    Width\n",
    "    Height\n",
    "    Depth\n",
    "\n",
    "During forward propagation, each filter which is spatially small (along the width and height dimensions) and extends over the entire depth of the input volume to which it is applied, is translated or convoluted with the width and height of the input volume producing a 2D activation map (or a feature map) for that filter. As the filter moved along the input area, a scalar product operation is performed between the values of the filter and those of the input portion to which it is applied.\n",
    "\n",
    "The goal is to learn activated filers in the presense of some specific type of functionality in a given spatial region of the input. The queuing of all these feature maps (for all filters) and the depth dimension form the output volume of a convolution layer.\n",
    "\n",
    "Each element of this volume can be interpreted as the output of a neuron that observes only a small region of the input which shares it's parameters with other neurons that are in the same feature map. Because these values all come from the application of the same filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4941e7",
   "metadata": {},
   "source": [
    "Pooling Layers\n",
    "\n",
    "These layers are inserted into the network to reduce the spatial size (width and height) of current representations, as well as volumes in a specific network stage. This serves to reduce the number of parameters and the computational time of the network. It also monitors overfitting. A pooling layer operates on each depth slice of the input volume independently to resize it spatially.\n",
    "\n",
    "For each feature obtained in the convolutional step, a matrix will be built and we will find the maximum in each chosen matrix to shrink the entire input.\n",
    "\n",
    "Steps:\n",
    "\n",
    "    Pick a window size. ( 2 or 3 )\n",
    "    Pick a stride moving range of pixels. ( usually 2 )\n",
    "    Slide the window across the filtered images.\n",
    "\n",
    "For each window, the maximum value will be chosen.\n",
    "\n",
    "A pooling layer will divide input into regions and select a single representative value. (max pooling and average pooling)\n",
    "\n",
    "The max pool layer will select the maximum number of features that have been detected by the convolution layers that precede it. The output will check whether a hypothetical feature is present in a region of the previous layers or not but not exactly where.\n",
    "\n",
    "Hence, the idea is to allow the succesive layers to worn on larger selection of data. Max pooling allows for faster convergence rates and therefore, allow us to select higher invarient features to improve the generalization performance.\n",
    "\n",
    "Advantages of using pooling layer:\n",
    "\n",
    "    Reduce the calculation of subsequent layers.\n",
    "    Increase the robustness of the features with respect to spatial position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba1b45bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Basic CNN\n",
    "# Importing and loading all the necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# import keras\n",
    "from keras.preprocessing import image\n",
    "# and use \n",
    "# image.ImageDataGenerator()\n",
    "# image.load_img()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd0647c",
   "metadata": {},
   "source": [
    "We will use the MNIST digits dataset and we can access to this dataset via Keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "407aec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and reshape the images in a 4-dimensional matrix \n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Reshape\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Padding the images by 2 pixels\n",
    "x_train = np.pad(x_train, ((0, 0), (2, 2), (2, 2), (0, 0)), 'constant')\n",
    "x_test = np.pad(x_test, ((0, 0), (2, 2), (2, 2), (0, 0)), 'constant')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d994ab",
   "metadata": {},
   "source": [
    "The MNIST dataset includes training and test datasets. These datasets are composed of the grayscale images (integer arrays with shape (num_sample, 28, 28)) and the labels (integers in the range 0-9). Images are padded by 2 pixels because the input images were 32x32.\n",
    "\n",
    "The next step is model parameters need to be set and the depth of the image (number of channels) will be 1. The reason for that is these images are grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83453350",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.width = x_train[0].shape[0]\n",
    "image.height = x_train[0].shape[1]\n",
    "\n",
    "# Grayscale = 1 channel\n",
    "num_channels = 1\n",
    "seed = 98\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8cfa58",
   "metadata": {},
   "source": [
    "The next is training and test data variables will be declared and there will be various batch sizes for training and evaluation. these values can be changed depending on the physical memory that is available for training and evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f68ab3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "evaluation_size = 500\n",
    "epochs = 300\n",
    "eval_every = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78089af",
   "metadata": {},
   "source": [
    "Our images need to be normalized to change the values of all pixels to a common scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e65c40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a7c647",
   "metadata": {},
   "source": [
    "We will declare our model. We will have the feature extractor module composed of 2 convolutional/ReLu/max pooling layers followed by the classifier with fully connected layers. Also to get the classifer to work, we flatten the out of the feature extractor module. So we can use it in the classifier. We will use a softmax activation function at the last layer of the classifier. Softmax will turn numeric output (logits) into probabilities that sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "416c2fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = image.width\n",
    "image_height = image.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f3494b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.keras.Input(dtype=tf.float32, \n",
    "                            shape=(image_width, \n",
    "                                   image_height, \n",
    "                                   num_channels), name=\"INPUT\")\n",
    "\n",
    "# First conv-ReLu-MaxPool layer\n",
    "conv1 = tf.keras.layers.Conv2D(filters=6, \n",
    "                               kernel_size=5, \n",
    "                               padding=\"VALID\", \n",
    "                               activation=\"relu\", \n",
    "                               name=\"C1\")(input_data)\n",
    "\n",
    "max_pool1 = tf.keras.layers.MaxPool2D(pool_size=2, \n",
    "                                      strides=2, \n",
    "                                      padding=\"SAME\", \n",
    "                                      name=\"S1\")(conv1)\n",
    "\n",
    "# Second conv-ReLu-MaxPool layer\n",
    "conv2 = tf.keras.layers.Conv2D(filters=16, \n",
    "                               kernel_size=5, \n",
    "                               padding=\"VALID\", \n",
    "                               activation=\"relu\", \n",
    "                               name=\"C3\")(max_pool1)\n",
    "\n",
    "max_pool2 = tf.keras.layers.MaxPool2D(pool_size=2, \n",
    "                                      strides=2, \n",
    "                                      padding=\"SAME\", \n",
    "                                      name=\"S4\")(conv2)\n",
    "\n",
    "# Flatten layer\n",
    "flatten = tf.keras.layers.Flatten(name=\"FLATTEN\")(max_pool2)\n",
    "\n",
    "# First fully connected layer\n",
    "fully_connected1 = tf.keras.layers.Dense(units=120, \n",
    "                                         activation=\"relu\", \n",
    "                                         name=\"F5\")(flatten)\n",
    "\n",
    "# Second fully connected layer\n",
    "fully_connected2 = tf.keras.layers.Dense(units=84, \n",
    "                                         activation=\"relu\", \n",
    "                                         name=\"F6\")(fully_connected1)\n",
    "\n",
    "# Final fully connected layer\n",
    "final_model_output = tf.keras.layers.Dense(units=10, \n",
    "                                           activation=\"softmax\", \n",
    "                                           name=\"OUTPUT\")(fully_connected2)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_data, outputs=final_model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edc720c",
   "metadata": {},
   "source": [
    "Next we will compile the model using Adam (Adaptive Moment Estimation) optimizer. Adam uses adaptive learning rates and momentum that allows us to get to local minima faster and so, converge faster.\n",
    "\n",
    "Loss function is a method of evaluating how well your algorithm models your dataset. If your predictions are totally off, your loss function will output a higher number. If they're pretty good, it'll output a lower number.\n",
    "\n",
    "As our targets are integers and not in a one-hot-encoded format, we will use the sparse categorical cross-entropy loss function and then we will add an accuracy metric to determine how accurate the model is in each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9056520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "INPUT (InputLayer)           [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "C1 (Conv2D)                  (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "S1 (MaxPooling2D)            (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "C3 (Conv2D)                  (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "S4 (MaxPooling2D)            (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "FLATTEN (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "F5 (Dense)                   (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "F6 (Dense)                   (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "OUTPUT (Dense)               (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dd02e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
